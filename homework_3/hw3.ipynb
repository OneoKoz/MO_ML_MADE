{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключаем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.stats import norm as norm_d\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import svdvals\n",
    "import scipy\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from functions import *\n",
    "from algorithms import *\n",
    "from tests import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства продублируем здесь задачу, которую мы решаем\n",
    "$$\n",
    "F(x) = f(x) + R(x) = \\frac{1}{m}\\sum\\limits_{i=1}^m\\underbrace{\\left(\\log\\left(1 + \\exp\\left(-y_i\\cdot (Ax)_i\\right)\\right) + \\frac{l_2}{2}\\|x\\|_2^2\\right)}_{f_i(x)} + \\underbrace{l_1\\|x\\|_1}_{R(x)} \\to \\min\\limits_{x\\in\\mathbb{R}^n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединим подготовку данных в одну функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    filename = \"datasets/\" + dataset + \".txt\"\n",
    "\n",
    "    data = load_svmlight_file(filename)\n",
    "    A, y = data[0], data[1]\n",
    "    m, n = A.shape\n",
    "    \n",
    "    if (2 in y) & (1 in y):\n",
    "        y = 2 * y - 3\n",
    "    if (2 in y) & (4 in y):\n",
    "        y = y - 3\n",
    "    assert((-1 in y) & (1 in y))\n",
    "    \n",
    "    sparsity_A = A.count_nonzero() / (m * n)\n",
    "    return A, y, m, n, sparsity_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L(dataset, A):\n",
    "    filename = \"dump/\"+dataset+\"_L.txt\"\n",
    "    file_path = Path(filename)\n",
    "    if file_path.is_file():\n",
    "        with open(filename, 'rb') as file:\n",
    "            L, average_L, worst_L = pickle.load(file)\n",
    "    else:\n",
    "        sigmas = svds(A, return_singular_vectors=False)\n",
    "        m = A.shape[0]\n",
    "        L = sigmas.max()**2 / (4*m)\n",
    "        \n",
    "        worst_L = 0\n",
    "        average_L = 0\n",
    "        denseA = A.toarray()\n",
    "        for i in range(m):\n",
    "            L_temp = (norm(denseA[i])**2)*1.0 / 4\n",
    "            average_L += L_temp / m\n",
    "            if L_temp > worst_L:\n",
    "                worst_L = L_temp\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump([L, average_L, worst_L],file)\n",
    "    return L, average_L, worst_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Разреженность матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрите датасеты $\\texttt{a9a}$, $\\texttt{gisette}$, $\\texttt{australian}$ и ещё любых 2 датасета на ваш вкус из LIBSVM https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html. Для каждого выбранного датасета проанализируйте какой тип матрицы лучше использовать -- $\\texttt{csr_matrix}$ или $\\texttt{numpy.ndarray}$ -- чтобы вычислять для данного датасета \n",
    "\n",
    "1) полный градиент и\n",
    "\n",
    "2) стох. градиент (рассмотреть батчи размера 1, 10, 100).\n",
    "\n",
    "Как видно из формулы для подсчёта градиента \n",
    "$$\n",
    "\\nabla f(x) = -\\frac{1}{m}\\cdot\\frac{A^\\top y}{1+\\exp(y\\odot Ax)}  + l_2 x,\n",
    "$$\n",
    "и стох. градиента по батчу $S = \\{i_1,i_2,\\ldots,i_k\\}$\n",
    "$$\n",
    "\\frac{1}{k}\\sum\\limits_{j=1}^k \\nabla f_{i_j}(x) = -\\frac{1}{k}\\cdot\\frac{A_S^\\top y_S}{1+\\exp(y_S\\odot A_Sx)}  + l_2 x,\n",
    "$$\n",
    "необходимо выполнить умножение $A^\\top$ (или $A_S^\\top$) на вектор и умножение $A$ (или $A_S$) на вектор, чтобы посчитать градиент (стох. градиент). Поэтому анализировать предлагается следующим способом: генерируется 5 случайных векторов размерности $n$, а затем в цикле много раз вычисляются градиенты (стох. градиенты) в указанных точках. Количество подсчётов градиентов выбирайте исходя из того, чтобы все умножения при одном из типов хранения матрицы $A$ занимали от 10 до 40 секунд. Для подсчёта стох. градиентов заранее насэмплируйте при помощи функции $\\texttt{randint}$ большую выборку элементов от $0$ до $m-1$ (например, выборку размера $10^7$ элементов), а затем вырезайте из неё подряд идущие непересекающиеся куски длиной $r$, где $r$ -- размер батча. Для удобства считайте, что $l_2 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = \"a9a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию матрица $A$ хранится в формате $\\texttt{csr_matrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseA = A.toarray()\n",
    "print(type(A))\n",
    "print(type(denseA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насэмплируем индексов для батчей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_indices = randint.rvs(low=0, high=m, size=10000000, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример того, как выглядят тесты для полноградиентного случая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = norm_d.rvs(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_tests = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        logreg_grad(x, [A, y, 0, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        logreg_grad(x, [denseA, y, 0, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример тестов для случая стох. градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_of_tests = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        batch_ind = batch_indices[i*batch_size:(i+1)*batch_size]\n",
    "        logreg_grad(x, [A[batch_ind], y[batch_ind], 0, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        batch_ind = batch_indices[i*batch_size:(i+1)*batch_size]\n",
    "        logreg_grad(x, [denseA[batch_ind], y[batch_ind], 0, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируйте здесь результаты своих экспериментов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Прокс-оператор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте функцию, вычисляющую $\\text{prox}_R(x)$, где $R(x) = \\lambda \\|x\\|_1$, $\\lambda \\geq 0$. Ваша функция должна брать первым аргументом точку $x$, в которой нужно посчитать прокс, а вторым аргументом -- число $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишите код в этой ячейке\n",
    "def prox_R(x, lamb):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для контроля корректности вызовите фунцию $\\texttt{prox}\\_\\texttt{test}$ из файла $\\texttt{tests.py}$. Если какой-то из тестов будет не пройден, то функция вернёт массив $[x, \\lambda, \\text{prox}_{R}(x)]$, где $x$ и $\\lambda$ - параметры, на которых Ваша фукция выдала неправильный ответ, $\\text{prox}_{R}(x)$ - это правильный ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_test(prox_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3. SVRG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя заготовку, которая оставлена в файле $\\texttt{algorithms.py}$, имплементируйте $\\texttt{prox-SVRG}$ с мини-батчингом. Обратите внимание, что в методе можно передавать выборку индексов $\\texttt{indices}$ для контроля корректности работы. Однако если передавать $\\texttt{None}$ в качестве $\\texttt{indices}$, то в методе новые индексы тоже будут сэмплироваться не на каждй итерации. Сделано это осознанно: можн гораздо быстрее насэмплировать i.i.d. выборку размера, скажем, $N$ за один вызов функции, чем сэмплировать $N$ раз подряд выборку размера $1$. Это можно наглядно проверить. Для начала загрузим датасет $\\texttt{a9a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = \"a9a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нём 32561 функция в сумме. Предположим, что мы запускаем $\\texttt{prox-SGD}$ с размером батча $r = 1$ на $1000000$ итераций, что примерно 30 проходов по датасету, то есть не так уж и много. Давайте просэмплируем выборку размера $1000000$ за один раз и $1000000$ раз просэмплируем выборку размера $1$. Сначала просэмплируем сразу большую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "randint.rvs(low=0, high=m, size=1000000, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На это ушло 1-3 секунды (зависит от мощности компьютера). А теперь рассмотрим второй вариант. Запустите следущую ячейку, а затем можете сходить заварить себе чай..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000000):\n",
    "    randint.rvs(low=0, high=m, size=1, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, выгоднее сэмплировать сразу много индексов, чтобы не терять много времени на сэмплирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки корректности работы метода предлагается воспользоваться заранее сгенерированной выборкой индексов и запустить для неё $\\texttt{prox-SVRG}$ со следующими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrg_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства тестирования и построения графиков методов Вам предлагается использовать следующие функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция нужна для того, чтобы получить доступ к результатам работы метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results_from_file(filename, method, args):\n",
    "    if method == 'SVRG':\n",
    "        with open('dump/'+filename+'_SVRG_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])+\"_num_of_epochs_\"\n",
    "                  +str(args[3])\n",
    "              +\"_epoch_length_\"+str(args[4])+\"_batch_size_\"+str(args[5])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"SGD_const_stepsize\":\n",
    "        with open('dump/'+filename+'_SGD_const_stepsize_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\"_batch_size_\"+str(args[4])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"SGD_decr_stepsize\":\n",
    "        with open('dump/'+filename+'_SGD_decr_stepsize_gamma_'+str(args[0][0])+\"_decr_period_\"\n",
    "                  +str(args[0][1])+\"_decr_coeff_\"+str(args[0][2])\n",
    "                  +\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\"_batch_size_\"+str(args[4])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"prox-GD\":\n",
    "        with open('dump/'+filename+'_prox-GD_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"GD\":\n",
    "        with open('dump/'+filename+'_GD_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"FISTA\":\n",
    "        with open('dump/'+filename+'_FISTA'+\"_l2_\"+str(args[0])+\"_l1_\"+str(args[1])\n",
    "                  +\"_num_of_epochs_\"+str(args[2])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция нужна, чтобы выгрузить решение задачи для данного датасета при заданных $l_2$ и $l_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_solution(dataset, l2, l1, x_star, f_star):\n",
    "    filename = \"dump/\"+dataset+\"_solution_l2_\"+str(l2)+\"_l1_\"+str(l1)+\".txt\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump([x_star, f_star], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция нужна, чтобы выгрузить решение задачи для данного датасета при заданных $l_2$ и $l_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_solution(dataset, l2, l1):\n",
    "    with open('dump/'+dataset+'_solution_l2_'+str(l2)+\"_l1_\"+str(l1)+\".txt\", 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустите $\\texttt{prox-SVRG}$ с теми же параметрами, но на бОльшее число эпох. Сохраните $x^*$ и $f(x^*)$. Параметр $\\texttt{indices}$ выставляйте равным $\\texttt{None}$. Параметры $l_2$ и $l_1$ выбирайте согласно PDF-документу с заданиями. Посчитайте количество ненулевых значений в найденном решении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# задать параметры\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 500\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = False\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=None, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)\n",
    "print(\"Найденное значение: \", res['func_vals'][-1])\n",
    "print(\"Процент ненулевых координат в найденном решении: \", np.count_nonzero(res['last_iter'])/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# сохранить решение x_star и f_star\n",
    "save_solution(dataset, l2, l1, res['last_iter'], res['func_vals'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните найденное значение с тем, которое выдаёт стандартный солвер (сравните результаты для $l_1 = 0$ и $l_1 = \\frac{L}{1000}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param = [A, y, l2, True, l1]\n",
    "res_solver = minimize(F, x_init, args = param, jac=logreg_grad_plus_lasso, \n",
    "                      options={'maxiter':5000, 'disp':True}, tol=1e-10)\n",
    "\n",
    "print(res_solver.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторите эксперимент с $S = 3$, но передайте туда найденные при помощи $\\texttt{prox-SVRG}$ $x^*$ и $f(x^*)$ в качестве $\\texttt{x}{\\_}\\texttt{star}$ и $\\texttt{f}{\\_}\\texttt{star}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = read_solution(dataset, l2, l1)[0]\n",
    "f_star = read_solution(dataset, l2, l1)[1]\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = False\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая функция позволяет строить графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(args):\n",
    "    supported_modes_y = ['squared_distances', 'func_vals']\n",
    "    supported_modes_x = ['time', 'data_passes', 'iters']\n",
    "    \n",
    "    dataset = args[0]\n",
    "    filename = args[1]\n",
    "    mode_y = args[2]\n",
    "    mode_x = args[3]\n",
    "    figsize = args[4]\n",
    "    fontsize = args[5]\n",
    "    title = args[6]\n",
    "    methods = args[7]\n",
    "    \n",
    "    assert(mode_y in supported_modes_y)\n",
    "    assert(mode_x in supported_modes_x)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    marker = itertools.cycle(('+', 'd', 'x', 'o', '^', 's', '*', 'p', '<', '>', '^'))\n",
    "    \n",
    "    num_of_methods = len(methods)\n",
    "    for idx, method in enumerate(methods):\n",
    "        res = read_results_from_file(filename, method[0], method[1])\n",
    "        if method[3] == None:\n",
    "            length = len(res['iters'])\n",
    "        else:\n",
    "            length = method[3]\n",
    "        plt.semilogy(res[mode_x][0:length], res[mode_y][0:length] / res[mode_y][0], linewidth=2, marker=next(marker), \n",
    "            markersize = 20, \n",
    "            markevery=range(-idx*int(length/(10*num_of_methods)), len(res[mode_x][0:length]), int(length/10)), \n",
    "            label = method[0]+method[2])\n",
    "        \n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(2,1), loc=\"upper right\", fontsize=fontsize)\n",
    "    if mode_x == 'time':\n",
    "        plt.xlabel(r\"Time, $s$\", fontsize=fontsize)\n",
    "    if mode_x == 'sampled_grads':\n",
    "        plt.xlabel(r\"Number of sampled gradients / number of data samples\", fontsize=fontsize)\n",
    "    if mode_x == 'iters':\n",
    "        plt.xlabel(r\"Number of iterations\", fontsize=fontsize)\n",
    "    if mode_y == 'squared_distances':\n",
    "        plt.ylabel(r\"$\\frac{||x^k - x^*||_2^2}{||x^0 - x^*||_2^2}$\", fontsize=fontsize)\n",
    "    if mode_y == 'func_vals':\n",
    "        plt.ylabel(r\"$\\frac{f(x^k)-f(x^())}{f(x^0)-f(x^*)}$\", fontsize=fontsize)\n",
    "    \n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    _ = plt.yticks(fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"a9a\"\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "\n",
    "#это массив с методами и их парамтерами, для которых мы хотим построить графики\n",
    "#в кждом массиве внутри этого массива есть 4 элемента\n",
    "#первый элемент -- название метода\n",
    "#второй элемент -- [параметры, чтобы открыть файл]\n",
    "#третий элемент -- метка, которая будет использоваться в легенде графика (чтобы понимать, чему отвечает та или иная траектория)\n",
    "#четвёртый элемент -- None или целое число, если Вы хотите обрезать график справа\n",
    "methods = [\n",
    "         ['SVRG', [gamma, l2, l1, 3, int(2*m/10), 10], \n",
    "           ' третий аргумент', None],\n",
    "]\n",
    "mode_y = 'squared_distances'\n",
    "mode_x = 'time'\n",
    "figsize = (12, 8)\n",
    "fontsize = 20\n",
    "title = dataset+\", (m,n) = (\"+str(m)+\",\"+str(n)+\"), l2 = L/\"+str(int(L/l2))+\", l1 = L/\"+str(int(L/l1))\n",
    "\n",
    "args_for_plots = [dataset, filename, mode_y, mode_x, figsize, fontsize, title, methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(args=args_for_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте разные размеры батчей и разные $l_2$ и $l_1$, как это указано в задании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4. SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте $\\texttt{prox-SGD}$ с мини-батчингом и постоянным шагом. Имплементируйте $\\texttt{prox-SGD}$ с мини-батчингом и периодически уменьшающимся шагом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = sgd_const_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_const_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "gamma_schedule = [gamma, 1, 0.5]\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 10\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = sgd_decr_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma_schedule=gamma_schedule, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_decr_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если тесты пройдены успешно, то выполните эксперименты, описанные в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5. prox-GD, FISTA и GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте $\\texttt{prox-GD}$, $\\texttt{FISTA}$ и $\\texttt{GD}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "gamma = 1.0/((L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этото параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = prox_gd(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_gd_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этот параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = FISTA(filename=filename, x_init=x_init, A=A, y=y, L=L+l2, mu=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "gamma = 1.0/((L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этото параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = gd(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если тесты пройдены успешно, то выполните эксперименты, описанные в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6. Сравнение методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7. Эксперименты с другим датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
